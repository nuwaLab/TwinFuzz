{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CW2:\n",
    "    \"\"\" C&W Attack (L2), changed from:\n",
    "    https://github.com/tagomaru/ai_security/blob/\n",
    "    Attributes:\n",
    "        classifier (Model) : logits output\n",
    "        k (float): hyperparameter change of k\n",
    "        learning_rate (float): learning rate of the Adam Optimizer\n",
    "        binary_search_steps (int): Binary Search Steps\n",
    "        max_iterations (int): Max iteration numbers of the adversarial generation\n",
    "        initial_c (float): initial constant value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classifier, k = 0, learning_rate = 0.01,\n",
    "                            binary_search_steps = 9, max_iterations = 1000,\n",
    "                            initial_c = 0.01):\n",
    "\n",
    "        # Import the corresponding classifier and define the self.variable\n",
    "        self.classifier = classifier\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.binary_search_steps = binary_search_steps\n",
    "        self.initial_c = initial_c\n",
    "            \n",
    "    def is_satisfied_with_k(self, logits, target_class):\n",
    "        \"\"\"\n",
    "        with k value increased, logits will basically increase\n",
    "        「 k を加味したターゲットクラスの logit が最大」という制約を満たすか確認する。\n",
    "        ターゲットクラスの logit から k　を引いた値が他のどのクラスの logit よりも大きければ　True を返し、\n",
    "        そうでなければ、False を返す。\n",
    "        Args:\n",
    "            logits (ndarray): logits\n",
    "            target_class (ndarray): target class\n",
    "        Returns:\n",
    "            satisfied (bool): whether k satisfy the objective.\n",
    "        \"\"\"\n",
    "        logits = np.copy(logits)\n",
    "        logits[target_class] -= self.k\n",
    "        satisfied = np.argmax(logits) == target_class\n",
    "        return satisfied    \n",
    "    \n",
    "    def generate(self, model, original_image, target_class_ohe):\n",
    "        \"\"\"\n",
    "        Generate adversarial sample\n",
    "        Args:\n",
    "            original_image (ndarray): orginal shape -- (28, 28)\n",
    "            target_class_ohe (ndarray): target class corresponding one-hot encoder (10, )\n",
    "        Returns:\n",
    "            o_best_adv_image (ndarray): adversarial class -- (28,28)\n",
    "        \"\"\"\n",
    "\n",
    "        # set of the corresponding target class - argmax is used to find the best trusted class.\n",
    "        target_class = np.argmax(target_class_ohe)\n",
    "\n",
    "        # Define the orginal label\n",
    "        original_label = model.predict(np.expand_dims(original_image, 0))\n",
    "        original_label = np.argmax(original_label[0])\n",
    "        \n",
    "        # calcualte the shape of the original image\n",
    "        shape = original_image.shape\n",
    "               \n",
    "        # constant and its corresponding limit\n",
    "        c = self.initial_c\n",
    "        c_lower = 0\n",
    "        c_upper = 1e10\n",
    "\n",
    "        #  (tanh(w) + 1) / 2 correspoinding w\n",
    "        w = tf.Variable(np.zeros(shape, dtype=np.float32))\n",
    "        \n",
    "        # cast the corresponding tensor to the original image\n",
    "        original_image = tf.cast(original_image, dtype=tf.float32)\n",
    "\n",
    "        # generating adversarial samples\n",
    "        def build_objective():\n",
    "\n",
    "            # adversarial image generation\n",
    "            adv_image = (tf.tanh(w) + 1) / 2\n",
    "\n",
    "            # calculating objective\n",
    "            objective1 = tf.reduce_sum(tf.square(adv_image - original_image))\n",
    "\n",
    "            # calculating adversarial samples.logits\n",
    "            logits = self.classifier(tf.expand_dims(adv_image, axis=0))[0]\n",
    "\n",
    "            # calculating target classes logits\n",
    "            target_logit = tf.reduce_sum(target_class_ohe * logits)\n",
    "            \n",
    "            # maximum logits other than target classes; logits\n",
    "            other_max_logit = tf.reduce_max((1 - target_class_ohe) * logits + (target_class_ohe * np.min(logits)))\n",
    "          \n",
    "            # loss function 2\n",
    "            objective2 = c * tf.maximum(0.0, other_max_logit - target_logit + self.k)\n",
    "\n",
    "            # total loss function\n",
    "            objective = objective1 + objective2\n",
    "\n",
    "            return objective\n",
    "\n",
    "        # loss function \n",
    "        objective = lambda: build_objective()\n",
    "        \n",
    "        \n",
    "        o_best_objective1 = np.inf # initial value guess\n",
    "        o_best_adv_image = np.zeros(shape) # initialize\n",
    "        o_best_class = -1 # initialize\n",
    "        loop_i = 0 # We also need to initialize the loop counter\n",
    "        \n",
    "        # for loop \n",
    "        for outer_step in range(self.binary_search_steps):\n",
    "            \n",
    "    \n",
    "            best_objective1 = np.inf \n",
    "            best_class = -1 \n",
    "            \n",
    "            \n",
    "            prev_objective = np.inf # initialize prev_objective\n",
    "            \n",
    "            # define adam optimizer\n",
    "            opt = keras.optimizers.Adam(self.learning_rate)\n",
    "            \n",
    "            # Adam loop\n",
    "            for iteration in range(self.max_iterations):\n",
    "                \n",
    "\n",
    "                opt.minimize(objective, var_list=[w])\n",
    "                \n",
    "                # calculate the logits of the adversarial samples\n",
    "                adv_image = (tf.tanh(w) + 1) / 2\n",
    "                logits = self.classifier(tf.expand_dims(adv_image, axis=0))[0]\n",
    "\n",
    "                objective1 = tf.reduce_sum(tf.square(adv_image - original_image))\n",
    "\n",
    "                # check every 10%\n",
    "                if iteration % (self.max_iterations // 10) == 0:\n",
    "                    if objective() > prev_objective * 0.9999:\n",
    "                        break\n",
    "                    prev_objective = objective()\n",
    "                \n",
    "                \n",
    "                satisfied = self.is_satisfied_with_k(logits, target_class)\n",
    "\n",
    "               \n",
    "                if objective1 < best_objective1 and satisfied:\n",
    "                    best_objective1 = objective1\n",
    "                    best_class = target_class\n",
    "                    \n",
    "            \n",
    "                if objective1 < o_best_objective1 and satisfied:\n",
    "                    o_best_objective1 = objective1\n",
    "                    o_best_class = target_class\n",
    "                    o_best_adv_image = adv_image\n",
    "                    loop_i = iteration # Here, we check the number of iteration to be able to output it\n",
    "\n",
    "            \n",
    "            if best_class == target_class:\n",
    "                c_upper = c\n",
    "                c = (c_lower + c_upper) / 2\n",
    "\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                c_lower = c\n",
    "                if c_upper < 1e9:                   \n",
    "                    c = (c_lower + c_upper) / 2\n",
    "                else:\n",
    "                    c *= 10\n",
    "            \n",
    "            # print the output\n",
    "            print('Binary Search {0}/{1}'.format(outer_step + 1, self.binary_search_steps))\n",
    "            print('  L2 square: {0:.2f} - c: {1:.2f} - class: {2}'.format(o_best_objective1, c, o_best_class))\n",
    "            print(f\"original_label: {original_label}\")\n",
    "            print(f\"adv_label: {np.argmax(self.classifier(tf.expand_dims(o_best_adv_image, axis=0)).numpy().flatten())}\")\n",
    "\n",
    "\n",
    "        # Calculate the total perturbation\n",
    "        # r_tot = o_best_adv_image - original_image \n",
    "        # Generate adversarial label\n",
    "        # adv_label = np.argmax(self.classifier(tf.expand_dims(o_best_adv_image, axis=0)).numpy().flatten()) \n",
    "        # ori_label is the original label\n",
    "        # ori_label = original_label\n",
    "        # # pert_image\n",
    "        # pert_image = o_best_adv_image\n",
    "\n",
    "        '''\n",
    "        return value:\n",
    "        r_tot (total perturbation); loop_i (number of iteration)\n",
    "        ori_label (original label); adv_label (adversarial label); pert_image (adversarial image)\n",
    "        '''\n",
    "\n",
    "        return o_best_adv_image - original_image, loop_i, original_label, np.argmax(self.classifier(tf.expand_dims(o_best_adv_image, axis=0)).numpy().flatten()), o_best_adv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('/ssd-sata1/mwt/def_project/DiffRobOT/DiffRobOT/MNIST/LeNet5_MNIST.h5')\n",
    "# model_logits = keras.models.load_model('/ssd-sata1/mwt/def_project/DiffRobOT/DiffRobOT/MNIST/LeNet5_MNIST_logits.h5')\n",
    "model = keras.models.load_model('/ssd-sata1/mwt/def_project/DiffRobOT/DiffRobOT/attacks/ai_security/models/mnist.h5')\n",
    "model_logits = keras.models.load_model('/ssd-sata1/mwt/def_project/DiffRobOT/DiffRobOT/attacks/ai_security/models/mnist_logits.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "_, (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "X_test = X_test/255.0\n",
    "original_image = X_test[0]\n",
    "print(original_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f72bc1ee690>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(original_image, cmap=plt.cm.gray)\n",
    "# Save the image to the local directory\n",
    "#plt.savefig('original_image.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 241ms/step\n",
      "Prediction: 7 - score 99.91%\n"
     ]
    }
   ],
   "source": [
    "Y_hat = model.predict(np.expand_dims(original_image, 0)) # 推論結果\n",
    "original_class = np.argmax(Y_hat, axis=1)[0] # 分類結果\n",
    "original_score = np.max(Y_hat, axis=1)[0] # スコア\n",
    "\n",
    "# 分類結果とスコアを表示\n",
    "print('Prediction: {0} - score {1:.2f}%'.format(original_class, original_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n",
      "Prediction: 7 - logit 12.28\n"
     ]
    }
   ],
   "source": [
    "logits = model_logits.predict(np.expand_dims(original_image, 0)) # logits\n",
    "original_class_logits = np.argmax(logits, axis=1)[0] # 分類結果\n",
    "original_logit = np.max(logits, axis=1)[0] # オリジナルクラスの logit\n",
    "\n",
    "# 分類結果と logit を表示\n",
    "print('Prediction: {0} - logit {1:.2f}'.format(original_class_logits, original_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating adversarial \n",
      "start generating adversarial \n",
      "start generating adversarial \n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Binary Search 1/9\n",
      "  L2 square: inf - c: 0.10 - class: -1\n",
      "original_label: 7\n",
      "adv_label: 5\n",
      "Binary Search 2/9\n",
      "  L2 square: inf - c: 1.00 - class: -1\n",
      "original_label: 7\n",
      "adv_label: 5\n",
      "Binary Search 3/9\n",
      "  L2 square: 1.77 - c: 0.55 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "Binary Search 4/9\n",
      "  L2 square: 1.76 - c: 0.33 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "Binary Search 5/9\n",
      "  L2 square: 1.76 - c: 0.44 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "Binary Search 6/9\n",
      "  L2 square: 1.76 - c: 0.38 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "Binary Search 7/9\n",
      "  L2 square: 1.76 - c: 0.41 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "Binary Search 8/9\n",
      "  L2 square: 1.76 - c: 0.40 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "Binary Search 9/9\n",
      "  L2 square: 1.76 - c: 0.39 - class: 0\n",
      "original_label: 7\n",
      "adv_label: 0\n",
      "original_label\n",
      "7\n",
      "adv_label\n",
      "0\n",
      "maximum iter\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "print(\"start generating adversarial \")\n",
    "print(\"start generating adversarial \")\n",
    "print(\"start generating adversarial \")\n",
    "\n",
    "target_class_ohe = to_categorical(0, num_classes=10) # ターゲットクラスを 0 とする\n",
    "\n",
    "attack = CW2(model_logits, k=0) # k = 0 で CW2 のインスタンスを生成\n",
    "\n",
    "\n",
    "adv_image_k0 = attack.generate(model, original_image, target_class_ohe) # 敵対的サンプルを生成\n",
    "print(\"original_label\")\n",
    "print(adv_image_k0[2])\n",
    "print(\"adv_label\")\n",
    "print(adv_image_k0[3])\n",
    "print(\"maximum iter\")\n",
    "print(adv_image_k0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CW2:\n",
    "    \"\"\" C&W Attack (L2) による敵対的サンプルを生成\n",
    "    Attributes:\n",
    "        classifier (Model) : logits を出力するモデル\n",
    "        k (float): 自信を調整するパラメータ\n",
    "        learning_rate (float): Adam の学習率\n",
    "        binary_search_steps (int): バイナリサーチの回数\n",
    "        max_iterations (int): Adam の最大イテレーション回数\n",
    "        initial_c (float): c の初期値\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classifier, k = 0, learning_rate = 0.01,\n",
    "                            binary_search_steps = 9, max_iterations = 1000,\n",
    "                            initial_c = 0.001):\n",
    "\n",
    "        # 引数をすべてインスタンス変数にセット\n",
    "        self.classifier = classifier\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.binary_search_steps = binary_search_steps\n",
    "        self.initial_c = initial_c\n",
    "            \n",
    "    def is_satisfied_with_k(self, logits, target_class):\n",
    "        \"\"\"\n",
    "        「 k を加味したターゲットクラスの logit が最大」という制約を満たすか確認する。\n",
    "        ターゲットクラスの logit から k　を引いた値が他のどのクラスの logit よりも大きければ　True を返し、\n",
    "        そうでなければ、False を返す。\n",
    "        Args:\n",
    "            logits (ndarray): logits\n",
    "            target_class (ndarray): ターゲットクラス\n",
    "        Returns:\n",
    "            satisfied (bool): 制約を満たす場合は True、そうでなければ False\n",
    "        \"\"\"\n",
    "        logits = np.copy(logits)\n",
    "        logits[target_class] -= self.k\n",
    "        satisfied = np.argmax(logits) == target_class\n",
    "        return satisfied    \n",
    "    \n",
    "    def generate(self, original_image, target_class_ohe):\n",
    "        \"\"\"\n",
    "        敵対的サンプルを生成\n",
    "        Args:\n",
    "            original_image (ndarray): オリジナル画像 `(28, 28)`\n",
    "            target_class_ohe (ndarray): ターゲットクラスの One-Hot `(10, )`\n",
    "        Returns:\n",
    "            o_best_adv_image (ndarray): 敵対的サンプル `(28, 28)`\n",
    "        \"\"\"\n",
    "\n",
    "        # ターゲットクラスを変数にセット\n",
    "        target_class = np.argmax(target_class_ohe)\n",
    "        \n",
    "        # オリジナル画像の型を変数にセット\n",
    "        shape = original_image.shape\n",
    "               \n",
    "        # c とその下限値と上限値をセット\n",
    "        c = self.initial_c\n",
    "        c_lower = 0\n",
    "        c_upper = 1e10\n",
    "\n",
    "        #  (tanh(w) + 1) / 2 の w\n",
    "        w = tf.Variable(np.zeros(shape, dtype=np.float32))\n",
    "        \n",
    "        #  オリジナル画像を Tensor にキャスト\n",
    "        original_imgae = tf.cast(original_image, dtype=tf.float32)\n",
    "\n",
    "        # 目的関数を生成する\n",
    "        def build_objective():\n",
    "\n",
    "            # 敵対的サンプルを格納する変数\n",
    "            adv_image = (tf.tanh(w) + 1) / 2\n",
    "\n",
    "            # 目的関数1\n",
    "            objective1 = tf.reduce_sum(tf.square(adv_image - original_image))\n",
    "\n",
    "            # 敵対的サンプルの logits\n",
    "            logits = self.classifier(tf.expand_dims(adv_image, axis=0))[0]\n",
    "\n",
    "            # ターゲットクラスの logit\n",
    "            target_logit = tf.reduce_sum(target_class_ohe * logits)\n",
    "            \n",
    "            # ターゲットクラス以外の logit の最大値\n",
    "            other_max_logit = tf.reduce_max((1 - target_class_ohe) * logits + (target_class_ohe * np.min(logits)))\n",
    "          \n",
    "            # 目的関数2\n",
    "            objective2 = c * tf.maximum(0.0, other_max_logit - target_logit + self.k)\n",
    "\n",
    "            # 目的関数\n",
    "            objective = objective1 + objective2\n",
    "\n",
    "            return objective\n",
    "\n",
    "        # 目的関数を呼び出し可能な(callable)オブジェクトとしてセット\n",
    "        objective = lambda: build_objective()\n",
    "        \n",
    "        # 目的関数の最小化の過程で見つかった最小の objective1、敵対的サンプル、分類結果を格納する変数\n",
    "        o_best_objective1 = np.inf # 初期値として無限をセット\n",
    "        o_best_adv_image = np.zeros(shape) # 初期値としてすべての要素に0をセット\n",
    "        o_best_class = -1 # 初期値としてダミークラスをセット\n",
    "        \n",
    "        # バイナリサーチ用のループ\n",
    "        for outer_step in range(self.binary_search_steps):\n",
    "            \n",
    "            # バイナリサーチのステップ内で見つかった最小の objective1 と分類結果を格納する変数\n",
    "            best_objective1 = np.inf # 初期値として無限をセット\n",
    "            best_class = -1 # 初期値としてダミークラスをセット\n",
    "            \n",
    "            # objective を保存しておく変数\n",
    "            prev_objective = np.inf # 初期値として無限をセット\n",
    "            \n",
    "            # Adam のインスタンスを生成\n",
    "            opt = keras.optimizers.Adam(self.learning_rate)\n",
    "            \n",
    "            # Adam を実行するループ\n",
    "            for iteration in range(self.max_iterations):\n",
    "                \n",
    "                # Adam を実行\n",
    "                opt.minimize(objective, var_list=[w])\n",
    "                \n",
    "                # 敵対的サンプルの logits 取得\n",
    "                adv_image = (tf.tanh(w) + 1) / 2\n",
    "                logits = self.classifier(tf.expand_dims(adv_image, axis=0))[0]\n",
    "\n",
    "                objective1 = tf.reduce_sum(tf.square(adv_image - original_image))\n",
    "\n",
    "                # max_iterations の 10% ごとに objective を確認\n",
    "                if iteration % (self.max_iterations // 10) == 0:\n",
    "                    # objective にほとんど変化がない、もしくは増えている場合は Adam のループを抜ける\n",
    "                    if objective() > prev_objective * 0.9999:\n",
    "                        break\n",
    "                    # 次のステップの比較用に現在の objective を保存\n",
    "                    prev_objective = objective()\n",
    "                \n",
    "                # 制約を満たすか確認\n",
    "                satisfied = self.is_satisfied_with_k(logits, target_class)\n",
    "\n",
    "                # objective1 が、best_objective1 より小さく、制約も満たせば、best_objective1 と best_class を更新する\n",
    "                if objective1 < best_objective1 and satisfied:\n",
    "                    best_objective1 = objective1\n",
    "                    best_class = target_class\n",
    "                    \n",
    "                # objective1 が、o_best_objective1 より小さく、制約も満たせば、o_best_objective1, o_best_class, o_best_adv_image を更新する\n",
    "                if objective1 < o_best_objective1 and satisfied:\n",
    "                    o_best_objective1 = objective1\n",
    "                    o_best_class = target_class\n",
    "                    o_best_adv_image = adv_image\n",
    "\n",
    "            # 現在のバイナリサーチのステップで制約を満たしている場合\n",
    "            if best_class == target_class:\n",
    "                # c の上限値に現在の c をセットする\n",
    "                c_upper = c\n",
    "\n",
    "                # c に　「現在の c」　と　「c の下限値」　の平均値をセットする\n",
    "                c = (c_lower + c_upper) / 2\n",
    "\n",
    "            # 見つからなかった場合\n",
    "            else:\n",
    "                # c の下限値に現在の c をセットする\n",
    "                c_lower = c\n",
    "                if c_upper < 1e9:\n",
    "                    # c の上限値が 1e9 未満の場合は、c に　「現在の c」　と　「c の上限値」　の平均値をセットする\n",
    "                    c = (c_lower + c_upper) / 2\n",
    "                else:\n",
    "                    # それ以外は、c が大きくなりすぎないように、c を 10 倍する\n",
    "                    c *= 10\n",
    "            \n",
    "            # ログ出力\n",
    "            print('Binary Search {0}/{1}'.format(outer_step + 1, self.binary_search_steps))\n",
    "            print('  L2 square: {0:.2f} - c: {1:.2f} - class: {2}'.format(o_best_objective1, c, o_best_class))\n",
    "\n",
    "        # 敵対的サンプルを ndarray に変換して返す\n",
    "        return o_best_adv_image.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate() missing 1 required positional argument: 'target_class_ohe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-3af5481e05ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCW2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# k = 0 で CW2 のインスタンスを生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0madv_image_k0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_ohe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 敵対的サンプルを生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: generate() missing 1 required positional argument: 'target_class_ohe'"
     ]
    }
   ],
   "source": [
    "target_class_ohe = to_categorical(0, num_classes=10) # ターゲットクラスを 0 とする\n",
    "\n",
    "attack = CW2(model_logits, k=0) # k = 0 で CW2 のインスタンスを生成\n",
    "adv_image_k0 = attack.generate(original_image, target_class_ohe) # 敵対的サンプルを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論結果。 model_logits ではなく、model での推論である点に注意\n",
    "Y_hat_k0 = model.predict(np.expand_dims(adv_image_k0, 0))\n",
    "\n",
    "# スコア\n",
    "score_k0 = np.max(Y_hat_k0[0])\n",
    "\n",
    "# 分類結果\n",
    "class_k0 = np.argmax(Y_hat_k0[0])\n",
    "\n",
    "# L2\n",
    "L2_k0 = np.linalg.norm(adv_image_k0 - original_image)\n",
    "\n",
    "# 敵対的サンプルを表示\n",
    "plt.axis('off')\n",
    "plt.title('{0} - {1:.2f}% - {2:.2f}'.format(class_k0, score_k0 * 100, L2_k0))\n",
    "plt.imshow(adv_image_k0, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[2.47730628e-01 2.47928183e-05 9.15350765e-02 1.12918034e-01\n",
      "  3.40114129e-05 2.22814400e-02 1.27208068e-06 2.47563064e-01\n",
      "  2.46795654e-01 3.11160404e-02]]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f72b03d8310>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 推論結果。 model_logits ではなく、model での推論である点に注意\n",
    "Y_hat_k0  = model.predict(np.expand_dims(adv_image_k0[4], 0))\n",
    "print(Y_hat_k0)\n",
    "\n",
    "class_k0  = np.argmax(Y_hat_k0, axis = 1)[0]\n",
    "print(class_k0)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"no\")\n",
    "plt.imshow(adv_image_k0[4], cmap=plt.cm.gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
