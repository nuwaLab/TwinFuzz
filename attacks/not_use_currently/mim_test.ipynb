{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is tensorflow2 implement of The MomentumIterativeMethod attack.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils_attack import optimize_linear, compute_gradient\n",
    "from utils_attack import clip_eta\n",
    "\n",
    "\n",
    "\n",
    "def momentum_iterative_method(\n",
    "    model_fn,\n",
    "    x,\n",
    "    eps=0.3,\n",
    "    eps_iter=0.06,\n",
    "    nb_iter=10,\n",
    "    norm=np.inf,\n",
    "    clip_min=None,\n",
    "    clip_max=None,\n",
    "    y=None,\n",
    "    targeted=False,\n",
    "    decay_factor=1.0,\n",
    "    sanity_checks=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Tensorflow 2.0 implementation of Momentum Iterative Method (Dong et al. 2017).\n",
    "    Paper link: https://arxiv.org/pdf/1710.06081.pdf\n",
    "    :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "    :param x: input tensor.\n",
    "    :param eps: (optional float) maximum distortion of adversarial example\n",
    "              compared to original input\n",
    "    :param eps_iter: (optional float) step size for each attack iteration\n",
    "    :param nb_iter: (optional int) Number of attack iterations.\n",
    "    :param norm: (optional) Order of the norm (mimics Numpy).\n",
    "              Possible values: np.inf, 1 or 2.\n",
    "    :param clip_min: (optional float) Minimum input component value\n",
    "    :param clip_max: (optional float) Maximum input component value\n",
    "    :param y: (optional) Tensor with true labels. If targeted is true, then provide the\n",
    "              target label. Otherwise, only provide this parameter if you'd like to use true\n",
    "              labels when crafting adversarial samples. Otherwise, model predictions are used\n",
    "              as labels to avoid the \"label leaking\" effect (explained in this paper:\n",
    "              https://arxiv.org/abs/1611.01236). Default is None.\n",
    "    :param targeted: (optional) bool. Is the attack targeted or untargeted?\n",
    "              Untargeted, the default, will try to make the label incorrect.\n",
    "              Targeted will instead try to move in the direction of being more like y.\n",
    "    :param decay_factor: (optional) Decay factor for the momentum term.\n",
    "    :param sanity_checks: bool, if True, include asserts (Turn them off to use less runtime /\n",
    "              memory or for unit tests that intentionally pass strange input)\n",
    "    :return: a tensor for the adversarial example\n",
    "    \"\"\"\n",
    "    # model forward prediction:\n",
    "    # model_normal = tf.keras.models.load_model(model_path)\n",
    "    # model_logits = tf.keras.models.load_model(model_logits_path)\n",
    "\n",
    "    if norm == 1:\n",
    "        raise NotImplementedError(\n",
    "            \"This attack hasn't been tested for norm=1.\"\n",
    "            \"It's not clear that FGM makes a good inner \"\n",
    "            \"loop step for iterative optimization since \"\n",
    "            \"it updates just one coordinate at a time.\"\n",
    "        )\n",
    "\n",
    "    # Check if order of the norm is acceptable given current implementation\n",
    "    if norm not in [np.inf, 1, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf, 1, or 2.\")\n",
    "\n",
    "    asserts = []\n",
    "\n",
    "    # If a data range was specified, check that the input was in that range\n",
    "    if clip_min is not None:\n",
    "        asserts.append(tf.math.greater_equal(x, clip_min))\n",
    "\n",
    "    if clip_max is not None:\n",
    "        asserts.append(tf.math.less_equal(x, clip_max))\n",
    "\n",
    "    if y is None:\n",
    "        # Using model predictions as ground truth to avoid label leaking\n",
    "        y = tf.argmax(model_fn(x), 1)\n",
    "\n",
    "    # Initialize loop variables\n",
    "    momentum = tf.zeros_like(x)\n",
    "    adv_x = x\n",
    "\n",
    "    i = 0\n",
    "    while i < nb_iter:\n",
    "        # Define gradient of loss wrt input\n",
    "        grad = compute_gradient(model_fn, loss_fn, adv_x, y, targeted)\n",
    "\n",
    "        # Normalize current gradient and add it to the accumulated gradient\n",
    "        red_ind = list(range(1, len(grad.shape)))\n",
    "        avoid_zero_div = tf.cast(1e-12, grad.dtype)\n",
    "        grad = grad / tf.math.maximum(\n",
    "            avoid_zero_div,\n",
    "            tf.math.reduce_mean(tf.math.abs(grad), red_ind, keepdims=True),\n",
    "        )\n",
    "        momentum = decay_factor * momentum + grad\n",
    "\n",
    "        optimal_perturbation = optimize_linear(momentum, eps_iter, norm)\n",
    "        # Update and clip adversarial example in current iteration\n",
    "        adv_x = adv_x + optimal_perturbation\n",
    "        adv_x = x + clip_eta(adv_x - x, norm, eps)\n",
    "\n",
    "        if clip_min is not None and clip_max is not None:\n",
    "            adv_x = tf.clip_by_value(adv_x, clip_min, clip_max)\n",
    "        i += 1\n",
    "\n",
    "    if sanity_checks:\n",
    "        assert np.all(asserts)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return adv_x\n",
    "\n",
    "\n",
    "def loss_fn(labels, logits):\n",
    "    \"\"\"\n",
    "    Added softmax cross entropy loss for MIM as in the original MI-FGSM paper.\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 22:20:52.519395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 22:20:54.776238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2695 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2024-09-18 22:20:54.777012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 7735 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2024-09-18 22:20:54.777593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 7735 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:86:00.0, compute capability: 8.6\n",
      "2024-09-18 22:20:54.778136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 7735 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa9e8062c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the MNIST dataset and the model\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_test = np.expand_dims(x_test, axis = -1).astype(np.float32) / 255 # randomize the input dataset\n",
    "\n",
    "# Load the pre-trained model\n",
    "mnist_model_logits = tf.keras.models.load_model(\"/data/mwt/DiffRobOT/MNIST/LeNet5_MNIST.h5\")\n",
    "\n",
    "# Define a single MNIST image for testing\n",
    "test_image = x_test[0]  # Use the first test image\n",
    "test_label = y_test[0]  # Use the corresponding label\n",
    "print(test_label)\n",
    "test_image_np = test_image.squeeze()  # Remove batch and channel dimensions\n",
    "plt.axis('off')\n",
    "plt.title(\"test_image\")\n",
    "plt.imshow(test_image_np, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIQE score for the MNIST image: 25.983\n"
     ]
    }
   ],
   "source": [
    "# Compute for NIQE Score:\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import math\n",
    "import skimage\n",
    "\n",
    "gamma_range = np.arange(0.2, 10, 0.001)\n",
    "a = scipy.special.gamma(2.0/gamma_range)\n",
    "a *= a\n",
    "b = scipy.special.gamma(1.0/gamma_range)\n",
    "c = scipy.special.gamma(3.0/gamma_range)\n",
    "prec_gammas = a/(b*c)\n",
    "\n",
    "def aggd_features(imdata):\n",
    "    #flatten imdata\n",
    "    imdata.shape = (len(imdata.flat),)\n",
    "    imdata2 = imdata*imdata\n",
    "    left_data = imdata2[imdata<0]\n",
    "    right_data = imdata2[imdata>=0]\n",
    "    left_mean_sqrt = 0\n",
    "    right_mean_sqrt = 0\n",
    "    if len(left_data) > 0:\n",
    "        left_mean_sqrt = np.sqrt(np.average(left_data))\n",
    "    if len(right_data) > 0:\n",
    "        right_mean_sqrt = np.sqrt(np.average(right_data))\n",
    "\n",
    "    if right_mean_sqrt != 0:\n",
    "      gamma_hat = left_mean_sqrt/right_mean_sqrt\n",
    "    else:\n",
    "      gamma_hat = np.inf\n",
    "    #solve r-hat norm\n",
    "\n",
    "    imdata2_mean = np.mean(imdata2)\n",
    "    if imdata2_mean != 0:\n",
    "      r_hat = (np.average(np.abs(imdata))**2) / (np.average(imdata2))\n",
    "    else:\n",
    "      r_hat = np.inf\n",
    "    rhat_norm = r_hat * (((math.pow(gamma_hat, 3) + 1)*(gamma_hat + 1)) / math.pow(math.pow(gamma_hat, 2) + 1, 2))\n",
    "\n",
    "    #solve alpha by guessing values that minimize ro\n",
    "    pos = np.argmin((prec_gammas - rhat_norm)**2);\n",
    "    alpha = gamma_range[pos]\n",
    "\n",
    "    gam1 = scipy.special.gamma(1.0/alpha)\n",
    "    gam2 = scipy.special.gamma(2.0/alpha)\n",
    "    gam3 = scipy.special.gamma(3.0/alpha)\n",
    "\n",
    "    aggdratio = np.sqrt(gam1) / np.sqrt(gam3)\n",
    "    bl = aggdratio * left_mean_sqrt\n",
    "    br = aggdratio * right_mean_sqrt\n",
    "\n",
    "    #mean parameter\n",
    "    N = (br - bl)*(gam2 / gam1)#*aggdratio\n",
    "    return (alpha, N, bl, br, left_mean_sqrt, right_mean_sqrt)\n",
    "\n",
    "def ggd_features(imdata):\n",
    "    nr_gam = 1/prec_gammas\n",
    "    sigma_sq = np.var(imdata)\n",
    "    E = np.mean(np.abs(imdata))\n",
    "    rho = sigma_sq/E**2\n",
    "    pos = np.argmin(np.abs(nr_gam - rho));\n",
    "    return gamma_range[pos], sigma_sq\n",
    "\n",
    "def paired_product(new_im):\n",
    "    shift1 = np.roll(new_im.copy(), 1, axis=1)\n",
    "    shift2 = np.roll(new_im.copy(), 1, axis=0)\n",
    "    shift3 = np.roll(np.roll(new_im.copy(), 1, axis=0), 1, axis=1)\n",
    "    shift4 = np.roll(np.roll(new_im.copy(), 1, axis=0), -1, axis=1)\n",
    "\n",
    "    H_img = shift1 * new_im\n",
    "    V_img = shift2 * new_im\n",
    "    D1_img = shift3 * new_im\n",
    "    D2_img = shift4 * new_im\n",
    "\n",
    "    return (H_img, V_img, D1_img, D2_img)\n",
    "\n",
    "\n",
    "def gen_gauss_window(lw, sigma):\n",
    "    sd = np.float32(sigma)\n",
    "    lw = int(lw)\n",
    "    weights = [0.0] * (2 * lw + 1)\n",
    "    weights[lw] = 1.0\n",
    "    sum = 1.0\n",
    "    sd *= sd\n",
    "    for ii in range(1, lw + 1):\n",
    "        tmp = np.exp(-0.5 * np.float32(ii * ii) / sd)\n",
    "        weights[lw + ii] = tmp\n",
    "        weights[lw - ii] = tmp\n",
    "        sum += 2.0 * tmp\n",
    "    for ii in range(2 * lw + 1):\n",
    "        weights[ii] /= sum\n",
    "    return weights\n",
    "\n",
    "def compute_image_mscn_transform(image, C=1, avg_window=None, extend_mode='constant'):\n",
    "    if avg_window is None:\n",
    "      avg_window = gen_gauss_window(3, 7.0/6.0)\n",
    "    assert len(np.shape(image)) == 2\n",
    "    h, w = np.shape(image)\n",
    "    mu_image = np.zeros((h, w), dtype=np.float32)\n",
    "    var_image = np.zeros((h, w), dtype=np.float32)\n",
    "    image = np.array(image).astype('float32')\n",
    "    scipy.ndimage.correlate1d(image, avg_window, 0, mu_image, mode=extend_mode)\n",
    "    scipy.ndimage.correlate1d(mu_image, avg_window, 1, mu_image, mode=extend_mode)\n",
    "    scipy.ndimage.correlate1d(image**2, avg_window, 0, var_image, mode=extend_mode)\n",
    "    scipy.ndimage.correlate1d(var_image, avg_window, 1, var_image, mode=extend_mode)\n",
    "    var_image = np.sqrt(np.abs(var_image - mu_image**2))\n",
    "    return (image - mu_image)/(var_image + C), var_image, mu_image\n",
    "\n",
    "\n",
    "def _niqe_extract_subband_feats(mscncoefs):\n",
    "    # alpha_m,  = extract_ggd_features(mscncoefs)\n",
    "    alpha_m, N, bl, br, lsq, rsq = aggd_features(mscncoefs.copy())\n",
    "    pps1, pps2, pps3, pps4 = paired_product(mscncoefs)\n",
    "    alpha1, N1, bl1, br1, lsq1, rsq1 = aggd_features(pps1)\n",
    "    alpha2, N2, bl2, br2, lsq2, rsq2 = aggd_features(pps2)\n",
    "    alpha3, N3, bl3, br3, lsq3, rsq3 = aggd_features(pps3)\n",
    "    alpha4, N4, bl4, br4, lsq4, rsq4 = aggd_features(pps4)\n",
    "    return np.array([alpha_m, (bl+br)/2.0,\n",
    "            alpha1, N1, bl1, br1,  # (V)\n",
    "            alpha2, N2, bl2, br2,  # (H)\n",
    "            alpha3, N3, bl3, bl3,  # (D1)\n",
    "            alpha4, N4, bl4, bl4,  # (D2)\n",
    "    ])\n",
    "\n",
    "def get_patches_train_features(img, patch_size, stride=8):\n",
    "    return _get_patches_generic(img, patch_size, 1, stride)\n",
    "\n",
    "def get_patches_test_features(img, patch_size, stride=8):\n",
    "    return _get_patches_generic(img, patch_size, 0, stride)\n",
    "\n",
    "def extract_on_patches(img, patch_size):\n",
    "    h, w = img.shape\n",
    "    patch_size = np.int(patch_size)\n",
    "    patches = []\n",
    "    for j in range(0, h-patch_size+1, patch_size):\n",
    "        for i in range(0, w-patch_size+1, patch_size):\n",
    "            patch = img[j:j+patch_size, i:i+patch_size]\n",
    "            patches.append(patch)\n",
    "\n",
    "    patches = np.array(patches)\n",
    "    \n",
    "    patch_features = []\n",
    "    for p in patches:\n",
    "        patch_features.append(_niqe_extract_subband_feats(p))\n",
    "    patch_features = np.array(patch_features)\n",
    "\n",
    "    return patch_features\n",
    "\n",
    "def _get_patches_generic(img, patch_size, is_train, stride):\n",
    "    h, w = np.shape(img)\n",
    "    if h < patch_size or w < patch_size:\n",
    "        print(\"Input image is too small\")\n",
    "        exit(0)\n",
    "\n",
    "    # ensure that the patch divides evenly into img\n",
    "    hoffset = (h % patch_size)\n",
    "    woffset = (w % patch_size)\n",
    "\n",
    "    if hoffset > 0: \n",
    "        img = img[:-hoffset, :]\n",
    "    if woffset > 0:\n",
    "        img = img[:, :-woffset]\n",
    "\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    #img2 = scipy.misc.imresize(img, 0.5, interp='bicubic', mode='F')\n",
    "    img2 = skimage.transform.resize(img, [int(np.floor(h/2)), int(np.floor(w/2))],order=3)\n",
    "\n",
    "    mscn1, var, mu = compute_image_mscn_transform(img)\n",
    "    mscn1 = mscn1.astype(np.float32)\n",
    "\n",
    "    mscn2, _, _ = compute_image_mscn_transform(img2)\n",
    "    mscn2 = mscn2.astype(np.float32)\n",
    "\n",
    "\n",
    "    feats_lvl1 = extract_on_patches(mscn1, patch_size)\n",
    "    feats_lvl2 = extract_on_patches(mscn2, patch_size/2)\n",
    "\n",
    "    feats = np.hstack((feats_lvl1, feats_lvl2))# feats_lvl3))\n",
    "\n",
    "    return feats\n",
    "\n",
    "def niqe(inputImgData):\n",
    "    gamma_range = np.arange(0.2, 10, 0.001)\n",
    "    a = scipy.special.gamma(2.0/gamma_range)\n",
    "    a *= a\n",
    "    b = scipy.special.gamma(1.0/gamma_range)\n",
    "    c = scipy.special.gamma(3.0/gamma_range)\n",
    "    prec_gammas = a/(b*c)\n",
    "\n",
    "    patch_size = 96\n",
    "    #module_path = dirname(__file__)\n",
    "    module_path = \"/data/mwt/DiffRobOT/attacks/not_use_currently/niqe\"\n",
    "\n",
    "    # TODO: memoize\n",
    "    params = scipy.io.loadmat(join(module_path, 'data', 'niqe_image_params.mat'))\n",
    "    pop_mu = np.ravel(params[\"pop_mu\"])\n",
    "    pop_cov = params[\"pop_cov\"]\n",
    "\n",
    "\n",
    "    M, N = inputImgData.shape\n",
    "\n",
    "    # assert C == 1, \"niqe called with videos containing %d channels. Please supply only the luminance channel\" % (C,)\n",
    "    assert M > (patch_size*2+1), \"niqe called with small frame size, requires > 192x192 resolution video using current training parameters\"\n",
    "    assert N > (patch_size*2+1), \"niqe called with small frame size, requires > 192x192 resolution video using current training parameters\"\n",
    "\n",
    "\n",
    "    feats = get_patches_test_features(inputImgData, patch_size)\n",
    "    sample_mu = np.mean(feats, axis=0)\n",
    "    sample_cov = np.cov(feats.T)\n",
    "\n",
    "    X = sample_mu - pop_mu\n",
    "    covmat = ((pop_cov+sample_cov)/2.0)\n",
    "    pinvmat = scipy.linalg.pinv(covmat)\n",
    "    niqe_score = np.sqrt(np.dot(np.dot(X, pinvmat), X))\n",
    "\n",
    "    return niqe_score\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_array):\n",
    "    # Convert the MNIST image(28*28) to a larger size(e.g., 224*224)\n",
    "    image = Image.fromarray(image_array)\n",
    "    resized_image = image.resize((224,224), Image.BICUBIC)\n",
    "    return np.array(resized_image)\n",
    "\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select a sample image from the MNIST dataset\n",
    "mnist_image = x_test[0]  # Change the index to test different images\n",
    "\n",
    "# Preprocess the MNIST image\n",
    "resized_mnist_image = load_image(mnist_image)\n",
    "\n",
    "# Calculate NIQE score for the MNIST image\n",
    "niqe_score = niqe(resized_mnist_image)\n",
    "print(f'NIQE score for the MNIST image: {niqe_score:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 22:22:29.966082: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-09-18 22:22:31.428965: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8400\n",
      "2024-09-18 22:22:33.497596: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Run the MIM attack\n",
    "adv_image = momentum_iterative_method(\n",
    "    model_fn=mnist_model_logits,\n",
    "    x=tf.convert_to_tensor(np.expand_dims(test_image, axis=0)),  # Add batch dimension\n",
    "    eps=0.4,\n",
    "    eps_iter=0.08,\n",
    "    nb_iter=20,\n",
    "    norm=np.inf,\n",
    "    clip_min=0.0,\n",
    "    clip_max=1.0,\n",
    "    y=tf.convert_to_tensor([test_label]),  # True label, change if you want a targeted attack\n",
    "    targeted=False,\n",
    "    decay_factor=1.0,\n",
    "    sanity_checks=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Label: 7\n",
      "Adversarial Label: 3\n",
      "Total Perturbation (L2 norm): 7.6616034507751465\n",
      "Total Iterations: 10\n",
      "Adversarial Image: [[0.         0.         0.4        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16       0.         0.         0.32       0.4        0.4\n",
      "  0.4        0.4        0.         0.         0.         0.\n",
      "  0.4        0.         0.4        0.4       ]\n",
      " [0.         0.         0.32       0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24       0.08       0.4        0.16       0.4\n",
      "  0.4        0.4        0.4        0.24       0.         0.\n",
      "  0.         0.         0.4        0.24      ]\n",
      " [0.         0.         0.4        0.         0.4        0.4\n",
      "  0.4        0.4        0.4        0.4        0.4        0.\n",
      "  0.         0.4        0.4        0.4        0.         0.\n",
      "  0.         0.         0.4        0.4        0.4        0.\n",
      "  0.         0.         0.32       0.4       ]\n",
      " [0.4        0.         0.16       0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.4        0.4        0.4\n",
      "  0.39999998 0.32       0.4        0.4        0.         0.\n",
      "  0.         0.         0.4        0.4        0.4        0.4\n",
      "  0.         0.         0.32       0.4       ]\n",
      " [0.4        0.4        0.4        0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.4        0.4        0.4\n",
      "  0.32       0.4        0.4        0.4        0.         0.\n",
      "  0.         0.4        0.4        0.4        0.32       0.4\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.4        0.4        0.         0.4        0.         0.\n",
      "  0.         0.         0.         0.         0.4        0.24\n",
      "  0.4        0.4        0.4        0.4        0.39999998 0.16\n",
      "  0.08       0.4        0.08       0.4        0.4        0.4\n",
      "  0.         0.4        0.4        0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24\n",
      "  0.16       0.         0.4        0.4        0.4        0.08\n",
      "  0.4        0.         0.16       0.4        0.4        0.\n",
      "  0.24       0.4        0.4        0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.3294118  0.3254902  0.22352943 0.19215688 0.63529414 0.\n",
      "  0.         0.         0.4        0.4        0.4        0.4\n",
      "  0.4        0.         0.08       0.4        0.4        0.\n",
      "  0.32       0.         0.4        0.4       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         1.         1.         0.83607835 0.5960784  0.54509807\n",
      "  0.3764706  0.3764706  1.         1.         1.         1.\n",
      "  0.3764706  0.3764706  0.26666668 0.         0.         0.4\n",
      "  0.16       0.         0.4        0.4       ]\n",
      " [0.         0.         0.4        0.4        0.4        0.4\n",
      "  0.6627451  0.84705883 0.32       0.28705883 0.2392157  0.49019608\n",
      "  0.5960784  0.48235294 1.         1.         1.         0.90039206\n",
      "  0.49803922 1.         0.5960784  0.14901963 0.         0.4\n",
      "  0.4        0.         0.         0.4       ]\n",
      " [0.16       0.4        0.4        0.4        0.4        0.4\n",
      "  0.4        0.         0.         0.         0.         0.\n",
      "  0.24       0.45490196 0.6627451  0.02274521 0.         0.\n",
      "  0.         0.6000001  1.         0.01568627 0.         0.\n",
      "  0.4        0.4        0.         0.4       ]\n",
      " [0.39999998 0.32       0.         0.         0.         0.\n",
      "  0.4        0.         0.         0.         0.4        0.4\n",
      "  0.4        0.4        0.4        0.         0.         0.\n",
      "  0.         1.         1.         0.47058824 0.32       0.\n",
      "  0.         0.4        0.         0.32      ]\n",
      " [0.16       0.         0.24       0.         0.         0.\n",
      "  0.         0.         0.16       0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.39999998 0.         0.39999998\n",
      "  0.5137255  0.92       0.7254902  0.4        0.4        0.4\n",
      "  0.24       0.         0.         0.        ]\n",
      " [0.16       0.         0.24       0.         0.         0.\n",
      "  0.         0.         0.         0.         0.08       0.4\n",
      "  0.         0.         0.         0.4        0.4        0.90588236\n",
      "  1.         1.         0.57254905 0.4        0.4        0.16\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.4        0.4        0.08       0.         0.\n",
      "  0.         0.         0.         0.4        0.4        0.4\n",
      "  0.         0.         0.         0.         0.6313726  0.5764706\n",
      "  1.         0.6431373  0.4        0.4        0.4        0.\n",
      "  0.         0.         0.         0.16      ]\n",
      " [0.         0.         0.16       0.         0.         0.\n",
      "  0.08       0.         0.         0.         0.08       0.4\n",
      "  0.4        0.         0.         0.         0.12156865 0.6000001\n",
      "  1.         0.41960785 0.         0.32       0.         0.\n",
      "  0.08       0.         0.         0.        ]\n",
      " [0.4        0.4        0.08       0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4        0.         0.         0.40392157 1.\n",
      "  0.627451   0.4        0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.24       0.4        0.4        0.4        0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4        0.4        0.89411765 1.         1.\n",
      "  0.4        0.         0.         0.16       0.         0.16\n",
      "  0.4        0.4        0.16       0.        ]\n",
      " [0.         0.32       0.4        0.4        0.4        0.\n",
      "  0.         0.         0.         0.4        0.4        0.4\n",
      "  0.         0.         0.69411767 1.         1.         0.62352943\n",
      "  0.4        0.4        0.         0.         0.         0.\n",
      "  0.24       0.4        0.4        0.39999998]\n",
      " [0.24       0.         0.16       0.4        0.4        0.4\n",
      "  0.4        0.         0.         0.         0.4        0.4\n",
      "  0.4        0.         1.         1.         1.         0.32\n",
      "  0.16       0.         0.         0.         0.4        0.16\n",
      "  0.4        0.4        0.24       0.        ]\n",
      " [0.         0.         0.4        0.4        0.         0.4\n",
      "  0.4        0.         0.         0.         0.         0.\n",
      "  0.         0.39607844 0.5960784  0.45882353 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.4        0.4        0.4        0.        ]\n",
      " [0.32       0.4        0.24       0.         0.         0.\n",
      "  0.4        0.4        0.4        0.         0.         0.\n",
      "  0.         0.5960784  0.5960784  0.         0.         0.\n",
      "  0.         0.         0.         0.08       0.08       0.4\n",
      "  0.4        0.4        0.         0.        ]\n",
      " [0.4        0.4        0.16       0.         0.         0.\n",
      "  0.         0.         0.         0.08       0.         0.\n",
      "  0.47843137 0.5960784  0.13098052 0.         0.         0.\n",
      "  0.         0.         0.4        0.39999998 0.4        0.4\n",
      "  0.4        0.4        0.         0.        ]\n",
      " [0.4        0.4        0.         0.         0.         0.32\n",
      "  0.4        0.4        0.4        0.         0.4        0.12156865\n",
      "  0.5960784  0.5960784  0.6039216  0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.         0.         0.4\n",
      "  0.4        0.4        0.         0.        ]\n",
      " [0.4        0.4        0.4        0.4        0.         0.4\n",
      "  0.         0.4        0.4        0.4        0.6392157  1.\n",
      "  1.         1.         0.6039216  0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.32       0.         0.\n",
      "  0.4        0.4        0.         0.        ]\n",
      " [0.32       0.4        0.4        0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.4        0.8745098  1.\n",
      "  1.         0.45882353 0.5568628  0.         0.         0.16\n",
      "  0.4        0.4        0.4        0.32       0.4        0.4\n",
      "  0.4        0.4        0.4        0.4       ]\n",
      " [0.         0.         0.4        0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.4        0.8745098  1.\n",
      "  1.         0.07999998 0.         0.24       0.         0.\n",
      "  0.         0.         0.4        0.4        0.4        0.4\n",
      "  0.4        0.4        0.4        0.4       ]\n",
      " [0.         0.         0.         0.         0.         0.4\n",
      "  0.4        0.4        0.4        0.         0.         0.\n",
      "  0.         0.         0.4        0.4        0.         0.\n",
      "  0.         0.         0.         0.         0.08       0.4\n",
      "  0.4        0.4        0.4        0.        ]]\n",
      "NIQE score for the adv image: 27.309\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Load the required model\n",
    "mnist_model = tf.keras.models.load_model(\"/data/mwt/DiffRobOT/MNIST/LeNet5_MNIST.h5\")\n",
    "\n",
    "# Calculate total perturbation (in L2 norm)\n",
    "perturbation = np.linalg.norm(adv_image - test_image)\n",
    "total_perturbation = np.linalg.norm(perturbation)\n",
    "\n",
    "# Get original label\n",
    "original_label = np.argmax(mnist_model.predict(np.expand_dims(test_image, axis = 0)))\n",
    "# original_label = np.argmax(mnist_model_logits.predict(np.expand_dims(test_image, axis=0)))\n",
    "\n",
    "# Get adversarial label\n",
    "adv_label = np.argmax(mnist_model.predict(adv_image))\n",
    "# adv_label = np.argmax(mnist_model_logits.predict(adv_image))\n",
    "\n",
    "# Output results\n",
    "print(f\"Original Label: {original_label}\")\n",
    "print(f\"Adversarial Label: {adv_label}\")\n",
    "print(f\"Total Perturbation (L2 norm): {total_perturbation}\")\n",
    "print(f\"Total Iterations: {10}\")  # The number of iterations is specified by `nb_iter`\n",
    "\n",
    "# Convert the adversarial image back to numpy for visualization if needed\n",
    "adv_image_np = adv_image.numpy().squeeze()  # Remove batch and channel dimensions\n",
    "print(f\"Adversarial Image: {adv_image_np}\")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"no\")\n",
    "plt.imshow(adv_image_np, cmap=plt.cm.gray)\n",
    "\n",
    "def load_image(image_array):\n",
    "    # Convert the MNIST image(28*28) to a larger size(e.g., 224*224)\n",
    "    image = Image.fromarray(image_array)\n",
    "    resized_image = image.resize((224,224), Image.BICUBIC)\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Preprocess the MNIST image\n",
    "resized_adv_image = load_image(adv_image_np)\n",
    "\n",
    "# Calculate NIQE score for the MNIST image\n",
    "niqe_score_adv = niqe(resized_adv_image)\n",
    "print(f'NIQE score for the adv image: {niqe_score_adv:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
